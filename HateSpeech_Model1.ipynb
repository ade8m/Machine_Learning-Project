{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz02IvlUnLxS3OopLnIp3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ade8m/Machine_Learning-Project/blob/main/HateSpeech_Model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N_FJ3WrQjC8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "stemmer = nltk. SnowballStemmer(\"english\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('ggplot')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from wordcloud import WordCloud\n",
        "from sklearn. feature_extraction. text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn. tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('HateSpeech.csv');\n",
        "#To preview the data\n",
        "print(df. head())"
      ],
      "metadata": {
        "id": "2mgO4iB2d3DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "t5pecRG9u_mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "7gu4ivIEvNeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"labels\"] = df[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
        "df = df[[\"tweet\", \"labels\"]]\n",
        "print(df. head())"
      ],
      "metadata": {
        "id": "H-AVMDCqkUqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **We have used two important Natural Language processing terms, stopword and stemmer. Stopwords are the useless words (data), in natural language processing. We can avoid those words from the input. Stemming is the process of producing morphological variants of a root word. We have to find the stem word for each text better and easy prediction.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qk0EqI4A20ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a function to process the data\n",
        "import string;\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stopword = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "def clean (text):\n",
        " text = str (text). lower()\n",
        " text = re. sub('[.?]', '', text) \n",
        " text = re. sub('https?://\\S+|www.\\S+', '', text)\n",
        " text = re. sub('<.?>+', '', text)\n",
        " text = re. sub('[%s]' % re. escape(string. punctuation), '', text)\n",
        " text = re. sub('\\n', '', text)\n",
        " text = re. sub('\\w\\d\\w', '', text)\n",
        " text = [word for word in text.split(' ') if word not in stopword]\n",
        " text=\" \". join(text)\n",
        " text = [stemmer. stem(word) for word in text. split(' ')]\n",
        " text=\" \". join(text)\n",
        " return text\n",
        "df[\"tweet\"] = df[\"tweet\"]. apply(clean)\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "-lKbIezfo47z"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the data**\n",
        "\n",
        "**The next important step is to explore the dataset and divide the dataset into training and testing data.**\n",
        "\n"
      ],
      "metadata": {
        "id": "agj4DQ_x3fyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np. array(df[\"tweet\"])\n",
        "y = np. array(df[\"labels\"])\n",
        "cv = CountVectorizer()\n",
        "X = cv. fit_transform(x)\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "NKNBJxsJ3vqu"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`**Building the model**`\n",
        "\n",
        "`**After segregating the data, our next work is to find a good algorithm suited for our model. We can use a DecisionTreeClassifier for building the Hate Speech detection project. DecisionTreeClassifier are a type of Supervised Machine Learning used mainly for classification problems**`. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vCS1rWt5GAgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model building\n",
        "model = DecisionTreeClassifier()\n",
        "#Training the model\n",
        "model. fit(X_train,y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "9RsXWIkaGKHd",
        "outputId": "1ea24aa3-3f67-4c55-f227-45da46c49350"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**`Evaluating the results`**\n",
        "\n",
        "**`The final step in machine learning model building is prediction. In this step, we can measure how well our model performs for the test input`**.\n",
        "\n"
      ],
      "metadata": {
        "id": "7Szw5oJ_H799"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "y_pred = model. predict (X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9hmYGpKICPJ",
        "outputId": "2814771e-baf5-40dd-c199-59853bdea1ce"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
              "       'No Hate and Offensive Speech', 'Offensive Speech',\n",
              "       'Offensive Speech'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy Score of our model\n",
        "from sklearn. metrics import accuracy_score\n",
        "print (accuracy_score (y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6WAzlkRIb4X",
        "outputId": "57756a55-2934-4524-9780-49b4a2b78a0a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8793251008680768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the outcome\n",
        "inp = \"It is really awesome\"\n",
        "inp = cv. transform([inp]). toarray()\n",
        "print(model. predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PQTn_mmIoJd",
        "outputId": "6310db13-3333-4511-ef86-39f911a8c337"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No Hate and Offensive Speech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"it's nice\"\n",
        "inp = cv. transform([inp]). toarray()\n",
        "print(model. predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcKEXecqLwWJ",
        "outputId": "df1ba712-7df6-4b36-b617-ebed48b21a9c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No Hate and Offensive Speech']\n"
          ]
        }
      ]
    }
  ]
}